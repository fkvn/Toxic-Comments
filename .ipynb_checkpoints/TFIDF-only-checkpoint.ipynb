{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing files, packages and setting up data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv('Files/train.csv')\n",
    "test = pd.read_csv('Files/test.csv')\n",
    "\n",
    "# Fill the null cell with \"unknown\" values for both \"train\" and \"test\" data frame\n",
    "train['comment_text'].fillna('unknown', inplace=True) \n",
    "test['comment_text'].fillna('unknown', inplace=True)\n",
    "\n",
    "test_label = pd.read_csv('Files/test_labels.csv')\n",
    "\n",
    "# label columns\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "test_label[label_cols] = test_label[label_cols].replace(-1, 1)\n",
    "\n",
    "# test label\n",
    "y_test = test_label[label_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing the TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "\n",
    "# this will split s by symbols create a list of string\n",
    "def tokenize(s): \n",
    "    return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Tfid Text Vectorization\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize, min_df=3, max_df=0.9, strip_accents='unicode',\n",
    "                     use_idf=1, smooth_idf=1, sublinear_tf=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to create X_trains and X_tests list model after initializing TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec: TF-IDF model\n",
    "\n",
    "def produceTrainAndTestmodel(vec):\n",
    "    \n",
    "    # purposes of \"fit_transform\":\n",
    "    # 1. generates word counts for the words in your comment_text\n",
    "    # 2. train tfidf transformation\n",
    "    X_train = vec.fit_transform(train['comment_text'])\n",
    "    \n",
    "    # purposes of \"transform\":\n",
    "    # 1. Use the vec above (after train tfidf transformation)\n",
    "    #    to apply and calculate tf-idf scores without counts update \n",
    "    X_test = vec.transform(test['comment_text'])\n",
    "    \n",
    "    \n",
    "    # To store list of X_train and X_test based on each label.\n",
    "    X_trains = []\n",
    "    X_tests = []\n",
    "    \n",
    "    # Build X_train and X_test through each lable\n",
    "    for i, j in enumerate(label_cols):\n",
    "        y_train = train[j].values\n",
    "        \n",
    "        # ****** Naives Bayes Model ******* #\n",
    "        # to find out the probability of an event based on the previous events that occured\n",
    "        # In this case, we calculate probability of an event 1 or 0 given the list of events y_train\n",
    "        \n",
    "        # pr(1,y): calculate te avg of TFIDF of toxic sentences    \n",
    "        # pr(0,y): calculate te avg of TFIDF of nontoxic sentences\n",
    "        \n",
    "        p1 = X_train[y_train==1].sum(0)\n",
    "        pr1 = (p1+1) / ((y_train==1).sum()+1)\n",
    "\n",
    "        p0 = X_train[y_train==0].sum(0)\n",
    "        pr0 = (p0+1) / ((y_train==0).sum()+1)\n",
    "\n",
    "        # get log helps to increase the weight of the word appears in toxic sentence\n",
    "        r = np.log(pr1 / pr0)\n",
    "        \n",
    "        # ****** Naives Bayes Model ******* #\n",
    "\n",
    "        # multiply X_train with calculated weight (weight of the word appreas in toxic sentence) above\n",
    "        X_trainR = X_train.multiply(r)\n",
    "\n",
    "        # multiply X_test with calculated weight (weight of the word appreas in toxic sentence) above\n",
    "        X_testR = X_test.multiply(r);\n",
    "        \n",
    "        # add to the list\n",
    "        X_trains.append(X_trainR);\n",
    "        X_tests.append(X_testR);\n",
    "    \n",
    "    # return list of X_train and X_tests of each label\n",
    "    return X_trains, X_tests;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculate predictions when we apply a model (algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter: model of a algorithm\n",
    "\n",
    "# Return: array of predictions\n",
    "\n",
    "def FindPredictions(model):\n",
    "    # retreiving list of X_train and X_tests of each label\n",
    "    X_trains, X_tests = produceTrainAndTestmodel(vec);\n",
    "\n",
    "    # creating a y_predict array to store the predictions\n",
    "    y_predict = np.zeros((len(test), len(label_cols)))\n",
    "    \n",
    "    # calculate predictions through each label\n",
    "    for i, j in enumerate(label_cols):\n",
    "        y_train = train[j].values\n",
    "\n",
    "        # training model for each label\n",
    "        model.fit(X_trains[i], y_train)\n",
    "\n",
    "        # predict model for each lable and add to y_predict \n",
    "        # model.predict_proba(X_tests[i])[:,1] means the probabilities of getting the output as 1\n",
    "        y_predict[:,i] = model.predict_proba(X_tests[i])[:,1]\n",
    "        \n",
    "    # return array of predictions\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
